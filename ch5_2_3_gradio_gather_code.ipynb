{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathered Notebook\n",
    "\n",
    "This notebook was generated by the Gather Extension. The intent is that it contains only the code and cells required to produce the same results as the cell originally selected for gathering. Please note that the Python analysis is quite conservative, so if it is unsure whether a line of code is necessary for execution, it will err on the side of including it.\n",
    "\n",
    "**Please let us know if you are satisfied with what was gathered [here](https://aka.ms/gatherfeedback).**\n",
    "\n",
    "Thanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Triton Neo 16\\diffusion-teset\\venv\\lib\\site-packages\\diffusers\\utils\\outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torchvision\n",
    "from diffusers import DDPMPipeline, DDIMScheduler, UNet2DModel\n",
    "from tqdm.auto import tqdm\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464de0aa2182488bbb1acafd06e82d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_name = \"johnowhitaker/sd-class-wikiart-from-bedrooms\"\n",
    "image_pipe = DDPMPipeline.from_pretrained(pipeline_name).to(device)\n",
    "scheduler = DDIMScheduler.from_pretrained(pipeline_name)\n",
    "scheduler.set_timesteps(num_inference_steps=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_loss(images, target_color=(.1, .9, .5)):\n",
    "    target = (torch.tensor(target_color).to(images.device) * 2 - 1)\n",
    "    target = target[None, :, None, None]\n",
    "    error = torch.abs(images - target).mean()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#55FFAA 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298430cf58a44510b69f955c1bb15920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Triton Neo 16\\diffusion-teset\\venv\\lib\\site-packages\\diffusers\\models\\attention_processor.py:1244: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  hidden_states = F.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image, ImageColor\n",
    "def generate(color, guidance_loss_scale):\n",
    "    print(color, guidance_loss_scale)\n",
    "    target_color = ImageColor.getcolor(color, \"RGB\")\n",
    "    target_color = [a / 255 for a in target_color]\n",
    "    x = torch.randn(1, 3, 256, 256).to(device)\n",
    "    for i, t in tqdm(enumerate(scheduler.timesteps), total=len(scheduler.timesteps)):\n",
    "        model_input = scheduler.scale_model_input(x, t)\n",
    "        with torch.no_grad():\n",
    "            noised_pred = image_pipe.unet(model_input, t)['sample']\n",
    "        x = x.detach().requires_grad_()\n",
    "        x0 = scheduler.step(noised_pred, t, x).pred_original_sample\n",
    "        loss = color_loss(x0, target_color) * guidance_loss_scale\n",
    "        cond_grad = - torch.autograd.grad(loss, x)[0]\n",
    "        x = x.detach() + cond_grad\n",
    "        x = scheduler.step(noised_pred, t, x).prev_sample\n",
    "    grid = torchvision.utils.make_grid(x, nrow=4)\n",
    "    im = grid.permute(1, 2, 0).cpu().clip(-1, 1) * .5 + .5\n",
    "    im = Image.fromarray((im.numpy() * 255).astype(np.uint8))\n",
    "    return im\n",
    "inputs = [\n",
    "    gr.ColorPicker(label = 'color',value=\"#55FFAA\"),\n",
    "    gr.Slider(minimum=0, maximum=30, value=3, label=\"Guidance Loss Scale\"),\n",
    "]\n",
    "outputs = gr.Image(label=\"result\")\n",
    "demo = gr.Interface(\n",
    "    fn=generate,\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    examples=[\n",
    "        [\"#BB2266\", 3],\n",
    "        [\"#44CCAA\", 5],\n",
    "    ])\n",
    "demo.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
